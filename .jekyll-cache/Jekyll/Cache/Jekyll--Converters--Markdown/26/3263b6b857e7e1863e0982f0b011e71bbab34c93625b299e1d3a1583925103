I"<h2 id="information-storage">Information Storage</h2>
<p>현대 컴퓨터는 2진법으로 정보를 저장하고 연산을 처리한다. 사람에게 익숙한 10진법이 아닌 2진법을 채택한 이유는 2진법의 장점 때문이다. 2진법을 구현하려면 0과 1만 구현하면 된다. 예를 들어 구멍이 유무, 흑백, 자기장의 방향 등이다. 컴퓨터는 2진법을 전류의 세기로 구분한다. 0V면 0이고 1V면 1과 같은 형태를 떠올릴지 모르겠지만 이는 불가능하다. 현실적으로 전류의 오차도 존재하기 때문에 범위를 지정해서 0과 1을 구분한다. 또한 둘 사이에 0도 1도 아닌 지점이 존재해서 전류차가 커야만 둘을 구분하기 쉬울 것이다. 그래서 전류가 0~0.2V는 0이 되고, 0.9~1.1V는 1이 되는 식으로 만들어져있다. 또한 2진법은 이처럼 구현이 쉬울 뿐만 아니라 굉장히 효율적이다. 우선은 가지수가 적기 때문에 오류가 날 확률이 적다. 5진법을 1V안에 구현하려면 굉장히 빽빽해서 힘들 것이다. 게다가 이진법으로 만들어지는 논리체계는 가지수가 적어 회로구현도 매우 간단하다.</p>

<h3 id="bits--bytes">Bits &amp; Bytes</h3>
<p>2진법으로 나타낼 수 있는 하나의 자리수를 <strong>Bit</strong>라고 한다. Bit는 이름 그대로 너무 작아 효율적인 내용을 담을 수 없지만. 이 비트들을 모으면 충분히 큰 정보를 담을 수 있다. 그래서 컴퓨터는 주소를 지정할 수 있는 최소한의 크기를 새로운 단위로 정했다. 이를 <strong>Byte(= 8bits)</strong>라고 한다.</p>

<h3 id="hexadecimal">Hexadecimal</h3>
<p>1byte를 표현하는 방법은 다양하다. 2진법을 사용하면 $00000000<em>2$ ~ $11111111_2$까지 표현할 수 있다. 하지만 길이가 길어서 표현하기 어렵다. 10진수로 표현하기에도 이를 다시 비트로 바꿔줘야 하므로 번거롭다. 그 때문에 비트를 16진법으로 표현한다. 16진법은 1~9까지는 10진법과 동일하지만 10~15는 A~F로 표현한다. 예를 들어 $11111111_2$는 $FF</em>{16}$으로 표현한다. c에서는 16진법을 표현할 때, 앞에 0x를 붙인다. 예를 들어 $F92EB3_{16}$은 0xF92EB3으로 표현한다.</p>

<table>
  <thead>
    <tr>
      <th>Binary</th>
      <th>Decimal</th>
      <th>Hexadecimal</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0000</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <td>0001</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>0010</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <td>0011</td>
      <td>3</td>
      <td>3</td>
    </tr>
    <tr>
      <td>0100</td>
      <td>4</td>
      <td>4</td>
    </tr>
    <tr>
      <td>0101</td>
      <td>5</td>
      <td>5</td>
    </tr>
    <tr>
      <td>0110</td>
      <td>6</td>
      <td>6</td>
    </tr>
    <tr>
      <td>0111</td>
      <td>7</td>
      <td>7</td>
    </tr>
    <tr>
      <td>1000</td>
      <td>8</td>
      <td>8</td>
    </tr>
    <tr>
      <td>1001</td>
      <td>9</td>
      <td>9</td>
    </tr>
    <tr>
      <td>1010</td>
      <td>10</td>
      <td>A</td>
    </tr>
    <tr>
      <td>1011</td>
      <td>11</td>
      <td>B</td>
    </tr>
    <tr>
      <td>1100</td>
      <td>12</td>
      <td>C</td>
    </tr>
    <tr>
      <td>1101</td>
      <td>13</td>
      <td>D</td>
    </tr>
    <tr>
      <td>1110</td>
      <td>14</td>
      <td>E</td>
    </tr>
    <tr>
      <td>1111</td>
      <td>15</td>
      <td>F</td>
    </tr>
  </tbody>
</table>

<h3 id="byte-addressing">Byte Addressing</h3>
<p>바이트가 메모리에서 어떻게 사용되는지 이해하기 위해 <strong>Virtual Memory(가상 메모리)</strong>라는 개념을 사용한다. 메모리의 1byte를 <strong>Cell</strong>이라고 하는데, cell을 구분하기 위해 <strong>Address(주소)</strong>라는 고유값을 통해 참조할 수 있도록 해놓았다. 주소는 배열의 index처럼 작동해서 해당 주소의 값을 다룰 수 있게 해준다. 이 개념은 집주소와 동일하다. 아파트는 하나의 집(Cell)이 여러개 모여 있는 형태고 각각의 집을 주소(Address)로 구분해놓았다. 그래서 705호라는 주소가 주어지면 그 집을 방문할 수 있다.</p>

<h3 id="word-size">Word Size</h3>
<p>앞서 주소라는 개념을 설명했다. 그런데 주소의 길이는 얼마가 적당할까? 만약 주소의 길이가 8bits라면 이 주소가 표현할 수 있는 수는 0~255로 256가지를 나타낼 수 있다. 이처럼 컴퓨터의 주소의 크기를 <strong>Word Size</strong>라고 하는데, word size는 주소의 최대크기를 결정하는 굉장히 중요한 변수다. 앞서 8bits의 경우를 살펴봤는데, 256가지는 너무 적은 수다. 그래서 대부분의 컴퓨터는는 32bits 사용한다. 이 경우 주소공간의 크기는 4GB($2^32$bytes)가 된다. 일반화 하면 w-bits의 컴퓨터는 $0$~$2^{w-1}$까지의 주소를 표현할 수 있고, 총 $2^w$bytes 만큼의 공간을 만들게 된다.</p>

<p>4GB는 옛날에는 굉장히 많은 양이지만 요즘에는 그리 큰 양이 아니다. 대규모 계산이 필요한 고성능 컴퓨터는 더 큰 주소공간이 필요하다. 그래서 용량을 늘리기 위해 Word Size를 64bits로 만든 컴퓨터가 나오게 되었다. 64bits는 메모리 용량이 18EB(exabytes, $18.4 * 10^{18}$)로 굉장히 넉넉하다.</p>

<p>컴퓨터 정보들은 단위를 바이트를 쓰는데, 컴퓨터가 32bit인지 64bit인지에 따라 다른 바이트를 사용한다.특히 c에서 long과 pointer는 컴퓨터에 따라 바이트가 다르다. 아래는 데이터 타입에 따라 사용하는 바이트를 정리한 것이다.</p>

<table>
  <thead>
    <tr>
      <th>C Data Type</th>
      <th>Typical 32-bit</th>
      <th>Typical 64-bit</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>char</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>short</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <td>int</td>
      <td>4</td>
      <td>4</td>
    </tr>
    <tr>
      <td>long</td>
      <td>4</td>
      <td>8</td>
    </tr>
    <tr>
      <td>float</td>
      <td>4</td>
      <td>4</td>
    </tr>
    <tr>
      <td>double</td>
      <td>8</td>
      <td>8</td>
    </tr>
    <tr>
      <td>pointer</td>
      <td>4</td>
      <td>8</td>
    </tr>
  </tbody>
</table>

<h3 id="multibyte-ordering">Multibyte Ordering</h3>
<p>각 메모리가 Word Size로 나뉘는 것을 알았다. 이제 2가지를 정해야 한다. 첫번째는 <strong>Object(객체)[^1]</strong>의 주소를 어떻게 정할지, 그리고 메모리에 바이트를 어떻게 정렬할지다. 우선 객체의 주소는 사용된 바이트 중 가장 작은 주소를 사용한다. 그 이유는 대부분의 객체는 연속된 바이트로 정보를 저장하기 때문에 최소 주소의 위치를 알면 나머지 바이트의 주소도 알 수 있기 때문이다. 예를 들어 <code class="language-plaintext highlighter-rouge">int x</code>가 있고 x의 주소 <code class="language-plaintext highlighter-rouge">&amp;x</code>의 값이 0x100이면, int는 4bytes를 차지하므로 0x100, 0x101, 0x102, 0x103에 정보가 저장되어 있다.</p>

<p>바이트를 어떤 순서로 놓을지를 두고 2가지 방법이 있다. 먼저 w-bits의 정수를 비트로 표현하면 $[x_{w-1}, x_{w-2}, …, x_1, x_0]$로 나타낼 수 있다. 이 때 가장 중요한 자리는 $x_{w-1}$이고 가장 덜 중요한 자리는 $x_0$이다. 그 이유는 제일 왼쪽 비트는 sign을 정하고, 왼쪽에 있을 수록 더 큰 값을 표현하기 때문에 오른쪽보다 왼쪽수가 영향이 더 크다. 그래서 왼쪽에 있을 수록 더 중요한 비트가 된다. 이번에는 바이트 단위로 나눠 보겠다. 제일 중요한 바이트는 $[x_{w-1}, x_{w-2}, …, x_{w-8}]$가 되고 가장 덜 중요한 바이트는 $[x_7, x_6, …, x_1, x_0]$이다. 어떤 컴퓨터는 객체를 메모리에 저장할 때 가장 중요한 바이트 부터 저장하고, 또 어 떤 컴퓨터는 가장 덜 중요한 바이트 부터 저장한다. 가장 중요한 바이트가 앞에 오는 것을 <strong>Big Endian</strong>, 덜 중요한 바이트가 앞에 오는 것을 <strong>Little Endian</strong>이라고 한다.</p>

<p>대부분의 인텔 호환 컴퓨터는 리틀 엔디안 방식으로만 동작한다. 반면 대부분의 IBM과 Oracle 컴퓨터는 빅 엔디안을 채택했다. 최신 마이크로프로세서 칩들은 양쪽을 다 지원하도록 구성된 경우가 많지만. 대부분은 운영체제가 결졍되면 한쪽 방식으로 고정해서 사용한다. 예를 들어 대부분의 휴대폰은 두 방식을 운영할 수 있는 하드웨어를 사용하지만, 안드로이드와 IOS는 리틀 엔디안을 사용한다.</p>

<ul>
  <li>Big Endian: Sun, Mac</li>
  <li>Little Endian: x86, ios, windows, ARM Android</li>
</ul>

<p>바이트 순서는 굳이 다른 방법을 채택할 이유가 없기 때문에 하나의 방식을 일정하게 지키는 한 선택은 무관하다. 문제는 데이터가 네트워크를 통해 전송될 때 발생한다. 리틀 엔디안 컴퓨터에서 빅 엔디안 컴퓨터로 정보를 보낼 때 순서가 뒤바뀌는 일이 생긴다. 이런 문제를 없도록 데이터를 네트워크 표준으로 바꿔서 송수신하게 된다.</p>

<h3 id="boolean-algegra">Boolean Algegra</h3>
<p>비트는 bool연산자로 계산할 수 있다. 각각 And, Or, Not, Exclusive-Or(Xor)인데, 아래와 같은 연산을 한다.</p>

<table>
  <thead>
    <tr>
      <th>&amp;</th>
      <th>0</th>
      <th>1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>

<table>
  <thead>
    <tr>
      <th>|</th>
      <th>0</th>
      <th>1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>

<table>
  <thead>
    <tr>
      <th>~</th>
      <th>0</th>
      <th>1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td> </td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<table>
  <thead>
    <tr>
      <th>^</th>
      <th>0</th>
      <th>1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<p>위의 연산은 비트 벡터에도 적용된다. 이때, 연산은 각 비트마다 행한다.</p>

<p>e.g.)
|   |    And   |   |    or    |   |    Xor   |   |    Not   |
|—|———-|—|———-|—|———-|—|———-|
|   | 01101001 |   | 01101001 |   | 01101001 |   |          |
| &amp; | 01010101 || | 01010101 | ^ | 01010101 | ~ | 01010101 |
|   | 01000001 |   | 01111101 |   | 00111100 |   | 10101010 |</p>

<h3 id="sets">Sets</h3>
<p>프로그래밍을 하다보면 수학의 subset 개념을 써야하는 순간이 있다. 이를 간단하게 구현할 수 있는 방법이 있다. n개의 element가 있는 set $A = {0, 1, 2, …, n-1}$의 subset을 구하려고 한다. 복잡하게 생각할 것 없이 $a_j = 1$이면 j번째 element를 포함하는 경우를 표현한다고 하자. 아래 예시를 보면 좀 더 쉽게 알 수 있다.</p>

<ul>
  <li>01101001 = ${0, 3, 5, 6}$</li>
  <li>01010101 = ${0, 2, 4, 6}$</li>
  <li>00000000 = $\phi$</li>
  <li>11111111 = A</li>
</ul>

<p>Set의 operation도 앞에서 배운 비트 연산을 사용하면 쉽게 구현할 수 있다.</p>
<ul>
  <li>Intersection(&amp;)</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Union(</td>
          <td>)</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>Symmetric difference(^)</li>
  <li>Complement(~)</li>
</ul>

<p>e.g.)
$A = 01101001, B = 01010101$</p>
<ul>
  <li>A &amp; B = 01000001 = ${0, 6}$</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>A</td>
          <td>B = 01111101 = ${0, 2, 3, 4, 5, 6}$</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>A ^ B = 00111100 = ${2, 3, 4, 5 }$</li>
  <li>~A = 10010110 = ${1, 2, 4, 7}$</li>
</ul>

<h3 id="bit-level-operation">Bit Level Operation</h3>
<p>앞서 배운 <strong>&amp;, |, ~, ^</strong>는 int, char, long 등의 표현 방법과 상관없이 비트 단위로 이루어진다.</p>

<p>e.g.)</p>
<ul>
  <li>~0x41(0100 0001) -&gt; 0xBE(1011 1110)</li>
  <li>~0x00(0000 0000) -&gt; 0xFF(1111 1111)</li>
  <li>0x69(0110 1001) &amp; 0x55(0101 0101) -&gt; 0x41(0100 0001)</li>
  <li>
    <h3 id="logic-operation">Logic Operation</h3>
    <p>Bit Level Operation은 각 비트 단위로 했지만 <strong>Logic Operations(&amp;&amp;, ||, !)</strong>는 전체 비트로 연산을 진행한다.
e.g.)</p>
  </li>
  <li>!0x41 -&gt; 0x00</li>
  <li>!0x00 -&gt; 0x01</li>
  <li>
    <p>!!0x41 -&gt; 0x01</p>
  </li>
  <li>0x69 &amp;&amp; 0x55 -&gt; 0x0로</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>0x69</td>
          <td> </td>
          <td>0x55 -&gt; 0x01</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<h3 id="shift-operations">Shift Operations</h3>
<p>Left Shift: x « y
비트를 왼쪽으로 y만큼 민 후 빈 공간을 0으로 채운다.</p>

<p>e.g.)</p>
<ul>
  <li>01100010 « 3 -&gt; 00010000</li>
  <li>01100010 « 1 -&gt; 11000100</li>
</ul>

<p>Right Shift: x » y</p>
<ul>
  <li>Logical Shift
오른쪽으로 y만큼 민 후 빈 공간을 0으로 채운다.</li>
  <li>Arithmetic Shift
오른쪽으로 y만큼 민 후 빈 공간을 가장 왼쪽의 숫자로 채운다.</li>
</ul>

<p>e.g.)</p>
<ul>
  <li>101000010 Log.» 3 -&gt; 00010100</li>
  <li>101000010 Arith.» 3 -&gt; 11110100</li>
</ul>

<p>Logical Shift는 비트를 옮겼을 때, 범위를 벗어난 것을 없애고 남은 부분을 0으로 처리하므로 자연스럽다. 반면 Arithmetic Shift는 1로 채우기 때문에 부자연스러워 보인다. 이는 둘의 쓰임이 다르기 때문이다. Logical Shift는 말 그대로 비트를 움직이는 경우에 쓰인다. 즉, 비트 단위에서 의미가 있을 때 사용하게 된다. 하지만 Arithmetic Shift는 signed 수의 크기를 유지하기 위해 이용된다. 이후에 Sign Extension을 보게 될 것이다.</p>

<blockquote>
  <p><strong>Remark</strong><br />
만약 w-bits의 데이터 타입에서 $k \geq w$인 k만큼 shift를 하면 어떻게 될까? 대부분의 컴퓨터에서는 $k$ $mod$ $w$로 계산을 해서 너무 큰 범위에서 shift가 일어나지 않게 한다. 하지만 C 프로그램은 이를 보장하지 않기 때문에 항상 k값이 w보다 작도록 해야 한다.</p>
</blockquote>

<h2 id="integers">Integers</h2>
<p>처음 숫자를 배운다면 자연수를 배운 후에 음수 개념을 포함한 정수를 배우게 된다. 이는 수의 개념을 배우는 자연스러운 과정으로 컴퓨터 또한 둘을 표현할 수 있도록 자료형을 만들었다. 자연수는 <strong>Unsigned Integer</strong>라고 하고, 정수는 <strong>Signed Integer</strong>라고 한다. 이름을 보면 알겠지만 Natural Number과 Integer로 설정하지 않았다. 이는 수에 부호가 존재한다는 것을 강조하기 위함이다. 즉, 둘의 가장 큰 차이점은 부호가 존재한다는 것이다. 이 부호가 정수를 표현할 때 어떤 차이점을 만들어내는지가 이 장의 핵심이 될 것이다.</p>

<h3 id="unsigned-integer">Unsigned Integer</h3>
<p>w-bits의 데이터를 표시하는 비트 벡터 $\vec{x} = [x_{w-1}, x_{w-2}, …, x_1, x_0]$, where $x_i \in {0, 1}$라고 하자. 이 비트는 해석하는 방법에 따라 다른 값을 나타낸다. 우선 unsigned로 계산하는 함수를 $B2U_w$(w-bits Binary to Unsigned)라고 한다. 정확한 식을 표시하기 전에 unsigned의 개념을 설명하겠다. unsigned는 비트를 이진수로 계산한다. 예를 들어 1011은 11을 의미한다. 정확히 표현하면 $x_i$가 0이라면 $0\cdot2^i$을 의미하고 1이라면 $1\cdot2^i$를 의미한다. 이를 식으로 표현하면 아래와 같다.</p>
<ul>
  <li>Unsigned Integer $B2U_w(\vec{x}) \equiv \sum_{i=0}^{w-1} x_{i}\cdot2^i$</li>
</ul>

<p>e.g.)<br />
$B2U_4([1001]) = 1\cdot2^3 + 0\cdot2^2 + 0\cdot2^1 + 1\cdot2^0 = 9$<br />
$B2U_4([0101]) = 0\cdot2^3 + 1\cdot2^2 + 0\cdot2^1 + 1\cdot2^0 = 5$</p>

<p>$B2U_w$의 가장 큰 특징은 Bijective Function이라는 것이다. 이를 증명하기 위해 $B2U_w$를 정확히 써보겠다.</p>

<p>$B2U_w: {0,1}^w \rightarrow {0, 1, …, UMax_w}$, where $UMax_w \equiv \sum_{i=0}^{w-1}2^i$.</p>

<p>여기서 $B2U_w$가 bijection이라는 것은 곧, $y \in {0, 1, …, UMax_w}에서 B2U_w(x) = y인 x \in {0,1}^w$가 유일하다는 것을 보여야 한다. 이는 2진법 전개의 유일성을 응용하면 쉽게 증명할 수 있다.</p>

<p>proof)</p>

<p>By the division theorem, there exist $q_0$ and $r_0$ s.t. $y = q_0 \cdot 2 + r_0$, where $0 \leq r &lt; 2$. If $q_0$ is greater than 2 we can use division theorem again for $q_0$. Then $q_0 = q_1 \cdot 2 + r_1$. We can continue this process while quotient become smaller than 2. This will be ended with finite numbers because $q_0 &gt; q_1 &gt; … \geq 0$. Assume that y can be represented by different two ways.</p>

<p>Let $y = B2U_w(\vec{x}) = \sum_{i=0}^{w-1}2^i \cdot x_i = \sum_{i=0}^{w-1}2^i \cdot z_i$.</p>

<table>
  <tbody>
    <tr>
      <td>If we let $d_i = x_i - z_i$, then $\sum_{i=0}^{w-1}2^i \cdot d_i = 0$. But we assunme that two representation is different. So there exists i s.t. $d_i \neq 0$ and let k is smallest one. Then $\sum_{i=k}^{w-1}2^i \cdot d_i = 0$ and we divide it by $2^k$. Then $d_k = - 2 \cdot \sum_{i=0}^{w-2-k}2^i \cdot d_{i+k+1}$. This means that $2</td>
      <td>d_k$, however, $abs(d_k) = abs(x_k - z_k) &lt; 2$. So $d_k$ should be 0. But $d_k \neq 0$. Therefore, there is no minimal k and all $d_k$ = 0. This contradict with our assumption. Thus, the expression is unique and so $B2U_w$ is bijection.</td>
    </tr>
  </tbody>
</table>

<p>$B2U_w$가 bijection이므로 역함수가 존재한다. 이는 unsigned를 다시 비트 벡터로 바꾸는 함수로 $U2B_w$로 표시한다.</p>

<h3 id="twos-complement">Two’s Complement</h3>
<p>Signed Integer를 표현하는 방법은 여러 가지가 있지만, 일반적으로 <strong>Two’s Complement(2의 보수)</strong> 방법을 사용한다. 2의 보수는 가장 왼쪽의 비트가 부호를 표시하도록 하고 나머지 자리로 수를 표현하는 방법이다. 비트 벡터로 2의 보수를 계산하는 함수를 $B2T_w$로 쓰며 변환 방법은 아래와 같다.</p>

<ul>
  <li>Two’s Complement $B2T_w(\vec{x}) = -x_{w-1}\cdot2^{w-1} + \sum_{i=0}^{w-2}x_{i}\cdot2^i$</li>
</ul>

<p>2의 보수로 나타낼 수 있는 가장 작은 수는 $1000…0_2$이며 $TMin_w \equiv -2^{w-1}$로 쓴다. 반대로 가장 큰 값은 $01111…1_2$로 $TMax_w \equiv 2^{w-1}-1$이다. 여기서 2의 보수의 특징이 나타나는데, 양수와 음수의 범위가 비대칭이라는 점이다.</p>

<p>$B2U_w$처럼 $B2T_w$도 Bijective function이다. 그래서 2의 보수에서 다시 비트로 돌아갈 수 있다. 이 또한 중요한 특성이기 때문에 증명을 해보겠다.</p>

<p>proof)<br />
$B2T_w: {0,1}^w \rightarrow {TMin_w, …, TMax_w}$, where $TMax_w \equiv 2^{w-1}-1$ and $TMin_w \equiv -2^{w-1}$.</p>

<p>Let $X = {0,1}^w$ and $Y = {TMin_w, …, TMax_w}$.</p>

<p>When $y \geq 0$, significant bit should be 0 and so x is started with 0. Then $B2T_w$ is a function to change binary to decimal. So we $B2T_w = B2U_{w-1}$ and we know that $B2U$ is bijection.</p>

<p>Next let $y &lt; 0$. Then significant bit is 1 and x starts with 1.</p>

<p>$B2T_w(\vec{x}) = -1\cdot2^{w-1} + \sum_{i=0}^{w-2}x_{i}\cdot2^i$</p>

<p>If we add $2^{w}$ then, $B2T_w(\vec{x}) + 2^{w} = 2^{w-1} + \sum_{i=0}^{w-2}x_{i}\cdot2^i = B2U_w(\vec{x})$.</p>

<p>Let $f_w(x) = x + 2^w$, then $B2U_w(\vec{x}) = f_w \circ B2T_w(\vec{x})$. We know $f_w(x)$ is bijection because $f_w^{-1}(x) = -2^w$ exists. So the equation can be changes like this.</p>

<p>$B2T_w(\vec{x}) = f_w^{-1} \circ B2U_w(\vec{x})$</p>

<p>Composition of two bijective function is bijective function. Because $B2T_w$ and $f_w^{-1}$ are bijection, $B2T_w$ is bijection.</p>

<p>Therefore, regardless of sign of y, $B2T_w$ is bijective function.</p>

<p>$B2T_w$의 역함수는 $T2B_w$로 표시한다.</p>

<h3 id="numeric-ranges">Numeric Ranges</h3>
<ul>
  <li>Unsigned Values: 0 ~ $2^w-1$</li>
  <li>Two’s Complement Values: $-2^{w-1}$ ~ $2^{w-1}-1$</li>
</ul>

<h3 id="casting">Casting</h3>
<p>Casting은 비트의 자료형을 바꿔주는 것이다. 비트는 같지만 자료형이 달라지면 표현하는 숫자가 달라지게 된다. c에서는 직접 <code class="language-plaintext highlighter-rouge">(int) ux</code>와 같은 형태로 unsigned인 ux를 signed인 int 자료형으로 바꾸는 기능이 있다. 이를 <strong>Explicit Casting</strong>이라고 한다. Explicit Casting은 코드에서 직접 명시하기 때문에 확인하기 쉽다.</p>

<p>Casting의 변환 과정을 수학적으로 표현해보겠다. $TMin_w \leq x \leq TMax_w$인 정수 $x$가 있을 때, 이 x를 비트 벡터로 바꿔주는 함수 $T2B_w$를 앞서 살펴보았었다. 이 비트 벡터를 다시 $B2U_w$를 사용하면 unsigned int 값을 구할 수 있다. 이를 하나의 함수로 나타내면 $T2U_w(x) \equiv B2U_w(T2B_w(x))$가 된다. 마찬가지로 $0 \leq x \leq UMax_w$인 정수 $x$를 2의 보수 값으로 바꿔주는 함수 $U2T_w(x) \equiv B2T_w(U2B_w(x))$가 존재한다.</p>

<p>이번에는 Casting 함수식을 구해보겠다. 먼저 $B2U_w(\vec{x}) - B2T_w(\vec{x}) = 2^{w-1} \cdot x_{w-1} - (-2^{w-1} \cdot x_{w-1}) = 2^w \cdot x_{w-1}$가 된다. 정리하면 $B2U_w(\vec{x}) = B2T_w(\vec{x}) + 2^w \cdot x_{w-1}$이다. 이를 $T2U_w$의 정의에 사용해주면 $T2U_w(x) = B2U_w(T2B_w(x)) = B2T_w(T2B_w(x)) + 2^w \cdot x_{w-1} = x + 2^w \cdot x_{w-1}$이다. 이를 함수로 정리해주면 아래와 같다.</p>

<p>$
T2U_w(x) =
\begin{cases}
x + 2^{w-1}, &amp;{x &lt; 0} <br />
x, &amp;{x \geq 0}
\end{cases}
$</p>

<p>$U2T_w$도 비슷한 방법으로 구할 수 있다. $U2T_w = B2T_w(U2B_w(x)) = B2U_w(U2B_w(x)) - 2^w \cdot x_{w-1} = x - 2^w \cdot x_{w-1}$.</p>

<p>$
U2T_w(x) = 
\begin{cases}
x, &amp;{x \leq TMax_w} <br />
x - 2^w, &amp;{x &gt; TMax_w}
\end{cases}
$</p>

<p>다만 이 변환 함수로 직접 계산하는 일은 없다. 앞서 말했듯이 컴퓨터는 Casting을 지원하기 때문에 자료형만 바꿔주면 쉽게 바꿔줄 수 있다.</p>

<p>문제는 c는 자동으로 자료형을 바꿔주는 기능이 있다는 점이다. 특히, Signed와 Unsigned간의 계산은 signed가 unsigned로 바뀌어서 진행된다. 즉, signed + unsigned 같은 연산이 있으면 signed는 같은 비트를 가지는 unsigned 값으로 바뀌고 unsigned + unsigned 연산으로 처리된다. 이는 signed를 unsigned로 바꾸는 코드가 없어도 자동으로 진행되는데, 이처럼 별다른 표현 없이 자료형을 변화시키는 것을 <strong>Implicit Casting</strong>이라고 한다.</p>

<h3 id="sign-extension">Sign Extension</h3>
<p>w-bit 만큼의 수 x가 있을 때, 비트 자리 수를 w+k-bit로 늘리려고 한다. 이 때, 값을 그대로 유지하려고 한다. unsigned라면 추가한 자리를 0으로 채우면 된다. signed의 경우 제일 앞 자리를 그대로 쓰면 된다. unsigned는 당연하지만, signed는 따로 증명해야 한다. 다만 이를 증명하기 위해선 1자리만 늘리는 경우만 봐도 충분하다. 왜냐하면 k자리를 늘리는 것은 1자리를 늘리는 것을 k번 한 것과 동일하기 때문이다.</p>

<p>proof)</p>

<p>When x is positive, it is trivial. Because sign bit is 0 and the value doesn’t change at all. So we only consider about x is negative.
Let $x = -2^{w-1} + \sum_{i=0}^{w-2}a_{i}\cdot2^{i}$, where $a_i \in {0, 1}$.</p>

<p>$-2^{w-1} = -2^{w-1} + 0 = -2^{w-1} + (-2^{w-1} + 2^{w-1}) = (-2^{w-1} + -2^{w-1}) + 2^{w-1} = -2^{w} + 2^{w-1}$.</p>

<p>So, $x = -2^{w-1} + \sum_{i=0}^{w-2}a_{i}\cdot2^{i} = -2^{w} + 2^{w-1} + \sum_{i=0}^{w-2}a_{i}\cdot2^{i} = -2^{w} + \sum_{i=0}^{w-1}a_{i}\cdot2^{i}$</p>

<p>Therefore, we can expand 1-digit for x.</p>

<p>위의 경우를 간략하게 자리수를 늘리려면 부호bit를 복사해서 늘리면 된다고 기억하면 된다.</p>

<h3 id="truncation">Truncation</h3>
<p>반대로 k+w-bit인 수 x를 앞의 k자리만큼 지우면 어떤 일이 발생하는지 알아보자. unsigned, signed 모두 $mod$ $2^k$연산이 일어난 것과 동일한 결과가 나타난다. 다만 signed의 경우 값의 범위가 $0 ~ 2^k-1$이 아니라 $Tmin(-2^{k-1}) ~ TMax(2^{k-1}-1)$이므로 이 범위에 맞춘 값이 된다.</p>

<h3 id="addition">Addition</h3>
<p>컴퓨터는 수를 표현하는 비트 수가 정해져 있기 때문에 덧셈을 할 경우 그 크기를 벗어나기도 한다. 예를 들어 unsigned x, y는 그 범위가 $0 \leq x, y \leq 2^w-1$인데 그 합의 범위는 $0 \leq x + y \leq 2^{w+1}-2$가 된다. 이는 x+y가 기존의 w-bits로 표현할 수 없음을 의미한다. w+1-bits로 늘린다해도 다시 한 번 더한다면 w+2-bits로 늘려야 한다. 이처럼 계속 비트를 늘려갈 수는 없으므로 덧셈은 비트 수를 유지하게 만들어야 한다. 방법은 간단한데 w-bits를 벗어나는 비트는 버리는 것이다. 이는 modular 연산을 진행하는 것과 동일하므로 아래와 같이 생각할 수 있다.</p>

<ul>
  <li>Unsigned $UAdd_w(u, v) = u + v$ $mod$ $2^w$</li>
</ul>

<p>Signed의 경우에도 범위값을 벗어나는 Overflow가 일어난다. 이번에도 범위 밖의 비트를 없애서 데이터의 크기를 유지하려고 한다. Signed의 경우는 범위를 벗어나는 부분이 양수와 음수 둘 다 일어나기 때문에 더 복잡하다. 그런데 덧셈은 비트 단위에서는 unsigned와 동일하게 일어나기 때문에 unsigned로 덧셈을 진행하고 다시 2의 보수로 바꿔주면 된다. 그래서 Signed에서의 덧셈은 아래와 같다.</p>
<ul>
  <li>Signed $TAdd_w(u, v) = (int)((unsigned)u + (unsigned)v)$</li>
</ul>

<p>여기서 Unsigned는 수의 범위가 $0$ ~ $2^w - 1$이므로 mod로 쉽게 표현 가능하다. 하지만 Signed는 범위가 $-2^{w-1}$ ~ $2^{w-1}-1$이기 때문에 mod 또한 -값이 되어야 할 때가 있다.</p>

<p>e.g.)</p>
<ul>
  <li>$1011u$(11) + $0110u$(6) -&gt; $10001u$(17) -&gt; $0001$($17 \equiv 1$ $mod$ $16$)</li>
  <li>
    <p>$1011s$(-5) + $0110s$(6) -&gt; $10001s$(-15) -&gt;$0001$($-15 \equiv 1$ $mod$ $16$)</p>
  </li>
  <li>$1111u$(15) + $1100u$(12) -&gt; $11011u$(27) -&gt; $1011$($27 \equiv 11$ $mod$ $16$)</li>
  <li>$1111s$(-1) + $1100s$(-4) -&gt; $11011s$(-5) -&gt; $1011$($-5 \equiv -5$ $mod$ $16$)</li>
</ul>

<h3 id="multiplication">Multiplication</h3>
<p>Addition과 별로 다른 점은 없다. 하지만 비트가 크게 늘어나기 때문에 버리는 부분이 많을 수 있다.</p>

<h3 id="multiply--divide-with-shift">Multiply &amp; Divide with shift</h3>
<p>u « k는 자리수를 벗어나지 않는다면 $u * 2^k$가 된다. 대부분의 기계는 곱셈보다 shift가 더 빠르다. 그래서 상수 단위로 곱셈을 한다면 shift를 이용하는 것이 더 빠르다. 하지만 컴파일러가 자동적으로 더 빠른 연산이 가능하면 코드를 수정해서 바꿔주므로 굳이 이를 확인하며 진행하지 않아도 된다. 마찬가지로 u » k는 $\lfloor u/2^k \rfloor$가 된다.</p>

<h3 id="why-we-use-unsigned">Why we use Unsigned?</h3>
<p>지금까지 Signed와 Unsigned를 적어왔지만 결과적으론 Signed 연산도 잘 정의되어 있기 때문에 Unsigned의 필요성에 의구심이 생길 수 있다. 특히 Unsigned의 Implicit Casting은 생각하지도 못한 오류들을 내놓기도 하는데 아래 예를 보자.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>unsigned i;
for(i = cnt-2; i &gt;= 0; i--)
    a[i] += a[i+1];
</code></pre></div></div>
<p>위의 코드는 i가 unsigned이기 때문에 0보다 작아질 수 없고 for문이 계속 실행되게 된다.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#define DELTA sizeof(int)
int i;
for(i = CNT; i-DELTA &gt;= 0; i -= DELTA)
    ...
</code></pre></div></div>
<p>위의 코드도 문제가 될 수 있다. 얼핏 보기엔 잘 모를 수 있지만, sizeof의 반환값은 size_t 타입으로 unsigned value기 때문에, signed와 unsigned의 연산으로 취급되어서 결과값이 unsigned가 된다. 그리고 unsigned는 항상 0이상이기 때문에 조건을 항상 만족해서 계속 실행된다.</p>

<p>보다시피 코드에서 생각하지 못한 오류가 발생할 수 있고 이를 찾아내는 것은 생각보다 오랜 시간이 걸릴 수도 있다. 그래서 Unsigned를 쓰는 경우는 제한적인 것이 좋다. Modular Arithmetic을 실행하거나, Set을 표현할 때처럼 항상 양수만이 필요한 경우에는 Unsigned를 사용한다.</p>

<h2 id="floating-point">Floating Point</h2>
<p>지금까지는 정수를 어떻게 표현하는지를 배웠다. 그런데 실수를 표현하려면 어떻게 해야 할까? 수를 표현하는 방법으로 이진법을 사용했으므로, 정수 아래부분도 이진법으로 표현해보겠다. 실수를 이진법으로 표현하려고 할 때, 제일 먼저 떠올릴 수 있는 방법은 일부는 정수 부분을 표현하고 다른 부분은 소수점 아래를 표현하는 것이다. 즉, $b_i b_{i-1} … b_1 b_0 b_{-1} b_{-2} … b_{-j}$ 같은 비트로 $\sum_{k=-j}^i2^k \times b_k$를 표현하는 것이다. 이 방법은 $5 \frac{3}{4} = 101.11_2$과 $2 \frac{7}{8} = 10.111_2$처럼 표현가능한 것이 있는가 하면 $\frac{1}{3} = 0.[01]_2$처럼 끝없이 이어져서 표현할 수 없는 수도 존재한다. 또한 정수와 소수점 아래를 동시에 사용해서 표현할 수 있는 수의 범위가 협소하다. 특히 큰 수나 너무 작은 수는 표현할 수 없다. 이런 단점을 보완하기 위한 방법이 <strong>Floating Point(부동소수점)</strong>이다. 부동소수점은 값 V를 $V = x \times 2^y$ 형태로 인코딩한다. 이때 표현할 수 없는 수는 가까운 수로 근사해서 나타낸다. 이 방식은 매우 큰 수나 반대로 매우 작은 수를 인코딩할 때 유용하다.</p>

<h3 id="floating-point-representation">Floating Point Representation</h3>
<p>부동소수점은 $V = (-1)^s \times M \times 2^E$ 형태로 나타낸다.</p>
<ul>
  <li>$s$는 양수인지 음수인지를 다룬다.</li>
  <li>$M$은 $1 \leq M &lt; 2$ 또는 $0 \leq M &lt; 1$ 사이의 값이다.</li>
  <li>$E$는 2의 지수를 표현하는데, 음수값도 가능하다.</li>
</ul>

<p>부동소수점의 비트는 3개의 구역으로 나뉜다.</p>
<ul>
  <li>첫번째 비트 s는 부호 $s$를 인코딩한다.</li>
  <li>exp(=$e_{k-1}e_{k-2}…e_1e_0$)는 지수 $E$를 인코딩한다.</li>
  <li>frac(=$f_{n-1}f_{n-2}…f_1f_0$)는 M을 인코딩한다.</li>
</ul>

<p>이때 k와 n의 값은 비트에 따라 크기가 달라지는데 32bits 라면 k = 8, n = 23이 되고 64bits에서는 k = 11, n = 52가 된다. 인코딩된 값은 exp 값에 따라 3가지 방법으로 나뉜다.</p>

<h4 id="normalized-values정규화-값">Normalized Values(정규화 값)</h4>
<p>exp의 비트가 모두 0도 아니고 모두 1도 아닌 경우다. 이 경우 $E = exp - Bias$로 해석하는데 Bias는 $2^{k-1}-1$이다. 이렇게 하면 exp의 범위가 $1$ ~ $2^k-2$이므로 E의 범위는 $-2^{k-1}+2$ ~ $2^{k-1}-1$이 된다. frac은 f가 $0 \leq f &lt; 1$인 이진수 $0.f_{n-1}…f_1f_0$를 의미하고 $M = 1 + f$로 계산한다. 이렇게 하면 $1.f_{n-1}…f_1f_0$와 같기 때문에 1을 표현하는 비트를 추가로 얻을 수 있다.</p>

<p>이렇게 frac에서 1을 넣어주는 것으로 1비트륵 이득볼 수 있었지만 대신 문제가 생긴다. M값이 항상 1이상이기 때문에 0을 표현할 수 없게 된다. 그래서 exp가 0인 경우는 해석을 달리해서 0을 포함해야 한다.</p>

<p>여기서 한 가지 의문이 생긴다. 앞서 배운 Two’s Complement를 이용해서 E를 표현하면 될텐데 왜 Bias 표현을 사용하는 것일까? 여기서 만약 E를 Two’s Complement로 표현할 경우 비트 단위 연산에서 번거롭기 때문이다. Bias 표현방법으로 E는 가장 작은 지수는 000…00이고 가장 큰 수는 011…111로 표현된다. 만약 두 수를 비교하려고 할 때, Two’s Complement는 E부분을 따로 계산해줘야 한다. 반면 Bias로 표현한 것은 전체 비트를 앞에서부터 비교해주면 간단하게 비교할 수 있다.</p>

<h4 id="denormalized-values비정규화-값">Denormalized Values(비정규화 값)</h4>
<p>exp의 비트가 모두 0일 경우로, $E = 1 - Bias$, $M = f$로 계산한다. 앞서 말했듯이 비정규화 값은 0을 표현하기 위해 사용하는데, exp와 frac의 모든 비트가 0이면 된다. 그런데 부호비트 s에 따라 +0.0과 -0.0이 생기게 된다. 이 둘은 다른 수로 취급되는데 +0.0은 0에 아주 가깝지만 0보다는 큰 값을, -0.0은 0에 가깝지만 0보다 작은 값을 표시한다. 그리고 E를 계산할 때, $1- Bias$로 쓴 것이 부자연스러워 보일 수 있지만, 정규화 값에서 exp가 모두 0인 경우를 제외했기 때문에 가장 작은 exp가 1이 된다. 그래서 값이 자연스럽게 이어지게 하기 위해서 $1-Bias$를 사용한다.</p>

<h4 id="special-values특수-값">Special Values(특수 값)</h4>
<p>exp의 비트가 모두 1인 경우로, frac이 모두 0이면 무한대를 나타낸다. 이 또한 s값에 따라 $+\infty$와 $-\infty$로 나뉘는데, 매우 큰 값의 곱셈이나 0으로 나눌 때처럼 Overflow를 표시할 때 쓴다. frac이 0이 아니면 Nan이라 하며 “not a number”의 약어로, 결과값이 실수나 무한대가 아닐 때 반환되는 값이다.</p>

<h3 id="rounding">Rounding</h3>
<p>부동소수점 표기법은 제한된 범위의 값만 나타낼 수 있으므로 연산 결과를 근사값으로 표시한다. 근사 방법은 Round-to-Even(짝수 근사법)을 사용하는데, 짝수 근사법은 이름 그대로 가장 가까운 짝수로 근사하는 방법이다. 예를 들어서 $1.4는 $1로 근사하고 $1.6은 $2로 근사한다. 이는 반올림과 다를바 없지만 중요한 것은 $1.5와 같은 중간값에서 나타난다. $1.5는 가장 가까운 짝수인 $2로 근사된다. $2.5는 반올림하면 $3이겠지만 가장 가까운 짝수는 $2이기 때문에 $2로 근사된다.</p>

<p>반올림이 아니라 짝수 근사법이 사용되는 것이 의아할 수도 있을 것이다. 이는 반올림을 사용할 경우 평균값이 약간 커지는 반면, 짝수 근사법은 평균값을 유지해준다. 마찬가지로 올림이나 버림 또한 평균을 커지게 하거나 작아지게 하기 때문에 쓰지 않는다.</p>

<h3 id="floating-point-calculation">Floating Point Calculation</h3>
<p>부동소수점 연산에서 중요한 사실은 교환법칙은 성립하지만 결합법칙은 성립하지 않는다는 것이다. 예를 들어 $(1 + 1e10)-1e10$은 계산하면 0.0이지만, $1 + (1e10 - 1e10)$ 은 1이 된다. 곱셈의 경우에도 교환법칙은 성립하지만 결합법칙은 성립하지 않는다. 예를 들어 $(1e20 * 1e20) * 1e-20$은 $\infty$가 되지만, $1e20 * (1e20 * 1e-20)$은 1e20이 된다. 또한 곱셈에서는 분배법칙도 성립하지 않는다. 예를 들어 $1e20 * (1e20-1e20)$은 0.0이지만, $1e20 * 1e20 - 1e20 * 1e20$은 NaN이 된다. 마지막으로 부동소수점의 특징은 monotone하다는 것이다. 즉, x가 NaN이 아니라면 $a /geq b$일때, $a + x \geq b + x$가 성립한다. 또한 $x /geq 0$이면 $a * x /geq b * x$가 성립하고 $x &lt; 0$이면 $a * x /leq b * x$가 성립한다.</p>

<p>부동소수점 계산에서 결합법칙과 분배법칙이 성립하지 않는다는 것은, 코드를 단축하려다가 예상하지 못한 오류를 발생시킬 가능성이 있다는 것이다. 그래서 코드를 작성할 때 주의해서 작성해야 한다.</p>

<p>구체적으로 계산이 일어나는 방식을 설명해보겠다. 우선 곱셈은 간단하게 sign끼리 Xor로 계산하고, M끼리 곱하고 E끼리 더하게 된다. 이때, M이 2이상이 되면 E를 증가시켜서 M을 2보다 작게 만들어 준다. 만약 E가 범위를 벗어나면 overflow가 일어난다. 마지막으로 계산이 끝나면 M을 근사하게 된다.</p>
<ul>
  <li>s = s1 ^ s2</li>
  <li>M = M1 x M2</li>
  <li>E = E1 + E2</li>
</ul>

<p>덧셈의 경우 E를 서로 동일한 수로 바꿔주고 그만큼 M을 shift해준다. 그리고 덧셈 연산을 진행한 후에 자리수를 넘어서는 것을 짝수 근사법으로 계산한다. 그렇게하면 정규화된 값을 얻을 수 있다.</p>

<hr />
<p>[1^]객체는 주소값을 가지는 데이터로 run-time memory에 저장된다. 객체의 type은 int, float, double 등이 있으며, class라는 프로그래머가 지정하는 타입으로도 만들 수 있다. 이 때, class로 object를 만들면 이를 클래스의 instance라고 한다. <a href="https://stackoverflow.com/questions/1093968/what-is-a-class-and-object-in-c/1093994">What is Class and Object?</a></p>
:ET