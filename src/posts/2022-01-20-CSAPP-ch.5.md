---
layout: post
title: "CS:APP Chapter.5"
date: 2022-01-20 11:02:09
categories: CSAPP
tag:
toc: true
---

# 5. Optimizing Program Performance

이번 장에선 프로그램을 최적화하는 방법을 알아볼 것이다.
프로그램 최적화를 위해선 여러 가지를 고려해야 한다.
적절한 알고리즘과 자료구조, 컴파일러의 능력과 한계, 병렬 계산 등을 알아야 한다.
그 중에서도 이 장에서는 컴파일러의 능력과 한계를 설명한다.
알고리즘과 자료구조는 다른 과목에서 배울 수 있고, 병렬 계산은 12장에서 알아볼 것이다.

이상적인 컴파일러는 비효율적인 코드를 가장 효율적인 형태로 변환 시켜야 한다.
하지만 아쉽게도 컴파일러는 코드를 최대한 효율적인 형태로 변환시키지 못한다.
그 때문에 프로그래머가 컴파일러의 한계를 배워야만 하는 것이다.
앞으로 이어질 절에서는 컴파일러가 효율적인 코드로 변환시키지 못하는 이유를 배운다.
그리고 이를 해결하기 위해선 프로그래머가 어떻게 코드를 작성해야 하는지도 배울 것이다.

최적화 작업은 프로세서의 설계와 특징에 따라 달라진다.
그렇기 때문에 별 차이 없는 변화가 효율을 크게 개선하는가 하면, 반대로 중요해 보이는 변화가 별다른 효과가 없을 수도 있다.
이 때문에 최적화 작업은 여러 조합을 직접 시도해보고 결과를 분석해야 한다.
이때 코드를 크게 변경시킨다면 바뀌는 부분이 많아져서 분석이 힘들다.
그러므로 우리는 코드를 조금씩 변화시키고 컴파일된 결과가 어떻게 변하는지 알아볼 것이다.

## 5.1 Capabilities and Limitations of Optimizing Compilers

GCC로 최적화를 진행할 때, 일반적으론 -02 수준을 사용한다.
그렇지만 우리는 컴파일러의 능력을 분석하고 있으므로, 변화를 보기 쉽도록 -01 수준을 적용했다.

### Memory Aliasing

컴파일러는 안전한 최적화만 진행한다.
이는 컴파일로 인해 코드가 본래의 목적과 다르게 작동하는 것을 막기 위해서다.
이해를 돕기 위해 아래의 두 예시를 보자.

```
void twiddle1(long *xp, long *yp)
{
    *xp += *yp;
    *xp += *yp;
}

void twiddle2(long *xp, long *yp)
{
    *xp += 2* *yp;
}
```

척 보기에는 두 프로시저는 동일하게 작동할 것 같다.
둘 다 *xp에 *yp를 두 번 더하고 있지만, twiddle2가 twiddle1보다 더 효율적이다.
왜냐하면 twiddle1은 *xp 읽기, *yp 읽기, \*xp 쓰기가 twiddle2보다 2배나 더 많기 때문이다.
twiddle2가 3번이면 족하게 하는 일을 twiddle1은 6번이나 하고 있으니 당연히 twiddle2가 효율적이게 보인다.
이런 논리 흐름에 따르면 컴파일러는 twiddle1을 twiddle2처럼 작동하도록 코드를 수정해야 한다.

하지만 예외 사항 때문에 컴파일러는 이런 일을 하지 않는다.
만약 yp가 xp가 동일하다고 해보자.
이 경우 twiddle1은 \*xp를 4배로 만드는 반면, twiddle2는 3배로 만든다.
컴파일러는 xp와 yp에 어떤 내용이 들어올지 전혀 알 수 없다.
그러므로 최대한 안전한 방식을 사용해야 하고, twiddle1의 코드를 twiddle2 방식으로 코드를 변화시키지 않는다.
이처럼 두 포인터가 같은 메모리를 가리킬 수 있는 경우를 **메모리 연결(Memory Aliasing)**이라고 한다.

### Function Call

또 다른 문제점은 함수 호출에서 발생한다.
아래의 예를 보자.

```
long f();

long func1() {
    return f() + f() + f() + f();
}

long func2() {
    return 4 * f();
}
```

둘 다 같은 계산을 하는 것처럼 보이지만 func1이 f를 4번 호출하는 반면, func2는 1번만 호출한다.
만약 f가 호출할 때마다 값이 변하는 내용이 있다면 문제가 생길 수 있다.
위 코드에 아래 내용을 추가한다고 생각해보자.

```
long counter = 0;

long f() {
    return counter++;
}
```

func1의 결과는 6이지만, func2는 0이다.
컴파일러는 각 함수 내부에 추가적인 효과가 있는지 검사하지 않는다.
만약 컴파일러가 함수 호출을 변경하면 위처럼 원하지 않는 효과가 생길 수 있다.
그래서 컴파일러는 함수 호출을 변경하지 않는다.

얼핏 보기에는 쉽게 이 방법을 해결할 수 있어 보인다.
간단하게 호출되는 함수를 내부에 붙여 넣는 것이다.
예를 들어서 위의 func1를 아래처럼 만드는 것이다.

```
long func1() {
    long t = counter++;
    t += counter++;
    t += counter++;
    t += counter++;
    return t;
}
```

다시 말해 함수 호출 부분을 대체해서 해당 함수의 내용을 그대로 적는 것이다.
이를 인라인 대체라고 하는데, 안타깝게도 GCC에선 이 방법으로는 해결되지 않는다.
GCC는 인라인 대체를 하나의 파일 내에서만 시도한다.
그래서 같은 파일 내부에서 함수가 선언되면 문제 없이 쓸 수 있지만, 다른 라이브러리에서 선언된 함수에는 적용할 수 없다.
우리는 -01 수준의 최적화로 진행하고 있으므로 인라인 대체 기법을 사용하지 않는다고 가정한다.

## 5.2 Expressing Program Performance

이번 절에선 프로그램의 성능을 표현하는 법을 알아보겠다.
이를 위해선 클럭(Clock Rate)과 CPE를 알아야 하는데 둘을 순서대로 설명하겠다.
프로세서의 성능은 클럭으로 표시한다.
클럭은 GHz를 단위로 사용하며, 1초에 몇 번의 사이클이 이뤄지는지 보여준다.
예를 들어 4GHz는 1초에 $4 \times 10^9$ 사이클이 동작된다는 의미다.

프로그램의 성능은 CPE(Cycles per Element)라는 단위로 표시한다.
CPE는 반복문이 포함된 프로그램의 성능을 표시하는데 적절한데, 어떻게 표현하는지 알기 위해 아래의 예시를 보자.

```
void psum1(float a[], float p[]. long n)
{
    long i;
    p[0] = a[0];
    for (i = 1; i < n; i++)
        p[i] = p[i-1] + a[i];
}

void psum2(float a[], float p[], long n)
{
    long i;
    p[0] = a[0];
    for (i = 1; i < n-1; i+=2) {
        float mid_val = p[i-1] + a[i];
        p[i]   = mid_val;
        p[i+1] = mid_val + a[i+1];
    }
    if (i < n)
        p[i] = p[i-1] + a[i];
}
```

두 함수는 p에 a의 원소의 누적합을 기록하는 함수다.
psum1은 매 번 하나의 계산을 수행한다.
psum2는 루프 풀기(loop unrolling)라는 기법을 사용해서 한 번에 2개의 계산을 한다.

위의 두 프로시저의 속도를 클럭으로 표시해보겠다.
psum1은 $368 + 9.0n$이고 psum2는 $368 + 6.0n$으로 근사된다.
여기서 프로그램의 성능은 n 앞의 계수와 크게 연관된다.
그렇기 때문에 n의 계수를 사용해서 성능을 비교한다.
CPE는 이 계수를 표시하는 것으로 psum1의 CPE는 9.0, psum2의 CPE는 6.0이다.
CPE가 낮을 수록 작업에 필요한 클럭 수가 적다는 의미다.
그러므로 psum2보다 psum1의 성능이 더 뛰어나다.

## 5.3 Program Example

첫 번째 절은 컴파일러가 한계가 있다는 것을 보여줬고, 두 번째 절은 단위를 소개하는데 그쳤다.
이번 절부터는 프로그램 최적화 단계를 보여준다.
이를 위해서 간단한 예시를 하나 보이고, 코드를 수정함에 따라 어떤 변화가 생기는지 볼 것이다.

우리는 예시로 벡터를 사용할 예정이다.
벡터 구조체를 선언하고 그와 함께 쓰일 함수를 선언할 것이다.
하지만 그다지 자세히 읽을 필요는 없다.
간단히 벡터와 거기에 쓰일 함수를 정의한다는 정도만 이해해도 좋다.
이후에 combine1에서 벡터를 사용하는 부분이 중요하므로 가볍게 넘어가자.

먼저 벡터 구조체를 아래처럼 만들어준다.

```
/* Create abstract data type for vector */
typedef struct {
    long len;
    data_t *data;
} vec_rec, *vec_ptr;
```

위 구조체는 길이와 데이터를 포함한다.
그리고 이름을 vec_rec이나 \*vec_ptr로 사용한다.
여기서 data_t는 아직 정해지지 않은 자료형으로 이후에 `#define long data_t` 같은 형태로 정하면 된다.
복잡하게 설명했지만 우리가 일반적으로 vector 라이브러리를 사용하는 것과 동일하다.
우리가 `vector<int>`로 int를 사용한다는 것을 선언하는 것처럼, data_t에 사용할 데이터 타입을 정할 뿐이다.

추가로 아래는 벡터에서 쓰이는 함수다.

```
/* Create vector of specified length */
vec_ptr new_vec(long len)
{
    /* Allocate header structure */
    vec_ptr result = (vec_ptr) malloc(sizeof(vec_rec));
    data_t *data = NULL;
    if (!result)
        return NULL; /* Couldn’t allocate storage */ result->len = len;
    /* Allocate array */
    if(len>0){
        data = (data_t *)calloc(len, sizeof(data_t));
        if (!data) {
            free((void *) result);
            return NULL; /* Couldn’t allocate storage */
        }
    }
    /* Data will either be NULL or allocated array */
    result->data = data;
    return result;
}

/*
 * Retrieve vector
 * Return 0 (out of bounds) or 1 (successful)
 */
 int get_vec_element(vec_ptr v, long index, data_t *dest)
{
    if (index < 0 || index >= v->len)
        return 0;
    *dest = v->data[index];
    return 1;
}

/* Return length of vector */
long vec_length(vec_ptr v)
{
    return v->len;
}
```

복잡해 보이지만 함수는 3가지 뿐이다.
벡터를 생성하는 함수, 원소를 읽는 함수, 길이를 읽는 함수 3종류다.

이제 본격적으로 컴파일러로 최적화하는 예시를 살펴보자.
우리는 아래의 combine1을 분석한다.

```
/* Implementation with maximum use of data abstraction */
void combine1(vec_ptr v, data_t *dest)
{
    long i;

    *dest = IDENT;
    for (i = 0; i < vec_length(v); i++) {
        data_t val;
        get_vec_element(v, i, &val);
        *dest = *dest OP val;
    }
}
```

combine1은 벡터 내의 원소를 모두 더하거나 곱하는 함수다.
여기서 data_t, IDENT, OP가 있는데, 이들은 따로 선언함으로써 함수의 형태가 달라진다.
예를 들어서 정수를 더하는 함수로 만들려고 한다고 하자.
그러면 `#define int data_t`, `#define 0 IDENT`, `#define + OP`라고 선언하면 된다.
위처럼 data_t, IDENT, OP를 정하지 않은 것은 모두 곱하거나 더하는 등의 함수가 형태가 동일하기 때문이다.
선언하는 내용만 바꾸면 같은 함수로 여러 함수를 만들 수 있으므로 번거롭게 여러 함수를 선언할 필요가 없다.

위 함수로 정수와 실수에서 값을 더하거나 곱한 함수를 만들 수 있다.
아래는 각 함수의 최적화 전후의 CPE를 측정한 값이다.

| Function | Methoid              | +(int) | \*(int) | +(float) | \*(float) |
| -------- | -------------------- | ------ | ------- | -------- | --------- |
| combine1 | Abstract unoptimized | 22.68  | 20.02   | 19.98    | 20.18     |
| combine1 | Abstract -01         | 10.12  | 10.12   | 10.17    | 11.14     |

최적화 후가 대략 2배 정도 효율이 상승한 것을 볼 수 있다.
이는 오직 컴파일러만 사용한 최적화로 아직 아무런 코드 변경이 없다.
그럼에도 -01 최적화만으로도 2배 정도 상승이 이뤄졌다는 점에서 컴파일러의 중요성을 알 수 있다.
다음 절에서는 combine1이 어떤 문제를 내포하고 있고, 또 이를 어떻게 고칠 수 있는지 살펴본다.

## 5.4 Eliminating Loop Inefficiencies

combine1을 보면 for문 안에서 vec_length를 사용한다.
그런데 벡터 길이가 변하지 않으므로 매 번 다시 계산하는 것은 낭비다.
이를 고친 함수 combine2는 아래처럼 된다.

```
/* Move call to vec_length out of loop */
void combine2(vec_ptr v, data_t *dest)
{
    long i;
    long length = vec_length(v);

    *dest = IDENT;
    for (i = 0; i < length; i++) {
        data_t val;
        get_vec_element(v, i, &val);
        *dest = *dest OP val;
    }
}
```

보다시피 vec_length를 계산하는 부분을 for문 밖으로 꺼내줬다.
combine2의 CPE를 다시 계산하면 아래처럼 된다.

| Function | Methoid         | +(int) | \*(int) | +(float) | \*(float) |
| -------- | --------------- | ------ | ------- | -------- | --------- |
| combine1 | Abstract -01    | 10.12  | 10.12   | 10.17    | 11.14     |
| combine2 | Move vec_length | 7.02   | 9.03    | 9.02     | 11.03     |

표를 보면 효율을 크게 개선한 경우도 있지만, 별로 영향이 없는 경우도 있다.
그렇지만 전체적인 경우를 보면 확실히 최적화 작업에 도움이 된다.

이 최적화 기법은 코드 이동(Code Motion)이라 알려준 종류 중 하나다.
코드 이동은 여러 번 계산하지만, 결과는 변하지 않는 것을 찾아낸다.
그리고 이를 코드의 앞부분으로 계산 횟수를 줄인다.

여기서 왜 컴파일러가 코드 이동을 자체적으로 실행하지 않는지 의문이 생긴다.
이는 이전에 설명했듯이, 컴파일러는 프로시저 호출을 변경하지 않는다.
프로시저를 호출함으로써 생기는 부가적인 효과들이 바뀔 수 있기 때문이다.
앞서 살펴봤듯이 함수를 호출할 때마다 값이 바뀐다면, 서로 다른 결과값이 나올 수 있다.
그러므로 컴파일러는 코드 이동을 자체적으로 하지 않는다.
프로그래머는 코드 이동을 직접 함으로써 코드를 개선해야 한다.

## 5.5 Reducing Procedure Calls

컴파일러는 프로시저 호출을 제대로 최적화하지 못한다.
그러므로 최대한 프로시저 호출을 줄여야만 성능을 개선할 수 있다.
combine2를 보면 반복문 내에서 get_vec_element를 사용한다.
get_vec_element는 매 번 i가 벡터 범위 안에 있는지를 확인한다.
하지만 이는 낭비인데, 코드상으로 절대 i가 범위 밖에 있을 수 없기 때문이다.

combine2를 개선하기 위해 get_vec_start 함수를 추가한다.
get_vec_start는 벡터의 시작 주소를 반환한다.
이를 사용하면 get_vec_element를 매 번 호출할 필요 없이 아래처럼 코드를 바꿀 수 있다.

```
data_t *get_vec_start(vec_ptr v) {
    return v->data;
}

/* Direct access to vector data */
void combine3(vec_ptr v, data_t *dest)
{
    long i;
    long length = vec_length(v);
    data_t *data = get_vec_start(v);

    *dest = IDENT;
    for(i = 0; i < length; i++) {
        *dest = *dest OP data[i];
    }
}
```

함수 호출을 줄였으므로 성능이 크게 개선될 것으로 기대된다.
아래는 combine2와 combine3의 CPE를 비교한 것이다.

| Function | Methoid         | +(int) | \*(int) | +(float) | \*(float) |
| -------- | --------------- | ------ | ------- | -------- | --------- |
| combine2 | Move vec_length | 7.02   | 9.03    | 9.02     | 11.03     |
| combine3 | Abstract -01    | 7.17   | 9.02    | 9.02     | 11.03     |

그런데 표를 보면 성능 개선이 전혀 없다.
오히려 약간 더 성능이 나빠졌다.
이 내용은 나중에 5.11.2에서 다시 다루는데, 왜 combine2의 i를 체크하는 방식이 성능 저하를 일으키지 않는지 배울 것이다.

## 5.6 Eliminating Unneeded Memory References

combine3의 어셈블리 코드를 보자.

```
/*
    Inner loop of combine3.  data_t = double, OP = *
    dest in %rbx, data+i in %rdx, data+length in %rax
*/
.L17:                               loop:
    vmovsd  (%rbx), %xmm0               Read product from dest
    vmulsd  (%rdx), %xmm0, %xmm0        Multiply product by data[i]
    vmovsd  %xmm0, (%rbx)               Store product at dest
    addq    $8, %rdx                    Increment data+i
    cmpq    %rax, %rdx                  Compare to data+length
    jne     .L17                        If !=, goto loop
```

combine3는 *dest에 값을 누적한다.
`*dest = *dest OP data[i];`를 보면 *dest의 값을 읽어들인 다음, 계산해서 다시 값을 넣어준다.
그 때문에 어셈블리 코드를 보면 (%rbx) 값을 %xmm0로 옮겨서 계산하고, 다시 (%rbx)로 옮겨주게 만들어진다.
그런데 이렇게 읽는 값이 이전의 값과 동일하기 때문에 상당히 낭비가 된다.
이런 낭비는 포인터를 사용하기 때문에 생기는 문제다.
해결하기 위해선 변수를 하나 선언해서 \*dest 대신에 사용하면 된다.

```
/* Accumulate result in local variable */
void combine4(vec_ptr v, data_t *dest)
{
    long i;
    long length = vec_length(v);
    data_t *data = get_vec_start(v);
    data_t acc = IDENT;

    for(i=0; i < length; i++){
        acc = acc OP data[i];
    }
    *dest = acc;
}
```

combine4의 어셈블리 코드는 아래처럼 된다.

```
Inner loop of combine4.  data_t = double, OP = *
acc in %xmm0, data+i in %rdx, data+length in %rax
.L25:                               loop:
    vmulsd  (%rdx), %xmm0, %xmm0        Multiply acc by data[i]
    addq    $8, %rdx                    Increment data+i
    cmpq    %rax, %rdx                  Compare to data+length
    jne     .L25                        If !=, goto loop
```

앞서 설명했던 불필요한 낭비가 없이 acc에 값을 누적하고 있다.
combine3와 combine4의 CPE를 비교하면 아래와 같다.

| Function | Methoid                 | +(int) | \*(int) | +(float) | \*(float) |
| -------- | ----------------------- | ------ | ------- | -------- | --------- |
| combine3 | Direct data access      | 7.17   | 9.02    | 9.02     | 11.03     |
| combine4 | Accumulate in temporary | 1.27   | 3.01    | 3.01     | 5.01      |

보다시피 성능이 크게 개선된 것을 볼 수 있다.

컴파일러가 combine3 코드를 combine4처럼 변경하지 않은 이유는 메모리 연결(Memory Aliasing) 때문이다.
이전에 설명했듯이 읽어들이고 쓰는 메모리가 중복되면 예상치 못한 결과가 나온다.
예를 들어서 v = [2, 3, 5]를 사용하고, IDENT = 1, OP = \*를 사용해보자.
그리고 combine3(v, get_vec_start(v) + 2)와 combine4(v, get_vec_start(v) + 2)를 비교해보자.
아래는 두 함수가 반복문이 진행되면서 v가 변하는 것을 표로 정리한 것이다.

| Function | Initial   | Before loop | i=0       | i=1       | i=2        | Final      |
| -------- | --------- | ----------- | --------- | --------- | ---------- | ---------- |
| combine3 | [2, 3, 5] | [2, 3, 1]   | [2, 3, 2] | [2, 3, 6] | [2, 3, 36] | [2, 3, 36] |
| combine4 | [2, 3, 5] | [2, 3, 5]   | [2, 3, 5] | [2, 3, 5] | [2, 3, 5]  | [2, 3, 30] |

보다시피 combine3는 계산 결과를 벡터에 누적하고 있으므로 값이 36이 된다.
반면 combine4는 변수에서 계산을 진행하고 벡터에 옮겨주므로 30이 된다.

물론 이런 예는 억지스럽다.
대부분 combine4처럼 작동할 것이라 생각하므로, 컴파일러가 combine4로 알아서 변환해줘야 한다고 생각할 수도 있다.
그렇지만 컴파일러는 프로그래머의 의도를 파악할 수 없다.
혹시라도 위와 같은 효과를 기대했을 수도 있으므로, 컴파일러는 안정적인 선택을 할 수 밖에 없다.
그래서 combine3처럼 문제가 생길 것 같은 코드를 수정하지 않는다.

## 5.7 Understanding Modern Processors
