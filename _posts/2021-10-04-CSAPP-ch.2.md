---
layout: post
title: "CS:APP Chapter.2"
date: Mon Oct  4 14:48:37 JST 2021
categories: CSAPP
tag: Arithmetic
toc: true
---
## Bits
컴퓨터는 2진법을 사용하는데 이는 0과 1만으로 표현하는 체계는 굉장히 단순해서 구현이 쉬울 뿐만 아니라 오류 발생이 적어 효율적이기 때문이다. 예를 들어 3진법을 쓴다고 하면 전기 신호의 경우의 수가 늘어나고, 신호를 구분하는데 더 많은 비용이 들어 비효율적이게 된다. 2진법을 구현할 수만 있다면 어떤 수단이든 상관 없다. 흑백으로 구분하거나, 구멍의 유무로 구분할 수도 있다. 하지만 컴퓨터는 전류의 세기로 0과 1을 구분한다. 기준선보다 전류가 약하면 0이 되고 더 강하면 1이 되는 방식이다. 예를 들어 0~0.2V는 0이 되고, 0.9~1.1V는 1이 된다. 0과 1로 표현되는 것을 **Bit**라고 하며 정보를 표현하는 가장 작은 단위다.

비트는 단순하지만 이진법으로 수를 표현하는데는 전혀 무리가 없다. 하지만 비트는 한 단위로 쓰기엔 너무 작기 때문에 8bits를 묶어서 **Byte(= 8bits)**라고 한다. 1byte를 표현하는 방법은 다양한 방법이 있다. 2진법을 사용하거나 길이가 너무 길어지면 16진법으로 표현하기도 한다. 예를 들어 $11111111_2$는 $FF_{16}$으로 표현한다. c에서는 16진법을 표현할 때, 앞에 0x를 붙인다. 예를 들어 $F92EB3_{16}$은 0xF92EB3으로 표현한다.

| Binary | Decimal | Hexadecimal |
|--------|---------|-------------|
| 0000 | 0 | 0 |
| 0001 | 1 | 1 |
| 0010 | 2 | 2 |
| 0011 | 3 | 3 |
| 0100 | 4 | 4 |
| 0101 | 5 | 5 |
| 0110 | 6 | 6 |
| 0111 | 7 | 7 |
| 1000 | 8 | 8 |
| 1001 | 9 | 9 |
| 1010 | 10 | A |
| 1011 | 11 | B |
| 1100 | 12 | C |
| 1101 | 13 | D |
| 1110 | 14 | E |
| 1111 | 15 | F |

컴퓨터 정보들은 단위를 바이트를 쓰는데, 컴퓨터가 32bit인지 64bit인지에 따라 다른 바이트를 사용한다.특히 c에서 long과 pointer는 컴퓨터에 따라 바이트가 다르다. 아래는 데이터 타입에 따라 사용하는 바이트를 정리한 것이다.

| C Data Type | Typical 32-bit | Typical 64-bit |
|-------------|----------------|----------------|
| char | 1 | 1 |
| short | 2 | 2 |
| int | 4 | 4 |
| long | 4 | 8 |
| float | 4 | 4 |
| double | 8 | 8 |
| pointer | 4 | 8 |

### Boolean Algegra
비트는 bool연산자로 계산할 수 있다. 각각 And, Or, Not, Exclusive-Or(Xor)인데, 아래와 같은 연산을 한다.

| & | 0 | 1 |
|---|---|---|
| 0 | 0 | 0 |
| 1 | 0 | 1 |

|\| | 0 | 1 |
|---|---|---|
| 0 | 0 | 1 |
| 1 | 1 | 1 |

| ~ | 0 | 1 |
|---|---|---|
|   | 1 | 0 |

| ^ | 0 | 1 |
|---|---|---|
| 0 | 0 | 1 |
| 1 | 1 | 0 |

위의 연산은 비트 벡터에도 적용된다. 이때, 연산은 각 비트마다 행한다.

e.g.)
|   |    And   |   |    or    |   |    Xor   |   |    Not   |
|---|----------|---|----------|---|----------|---|----------|
|   | 01101001 |   | 01101001 |   | 01101001 |   |          |
| & | 01010101 |\| | 01010101 | ^ | 01010101 | ~ | 01010101 |
|   | 01000001 |   | 01111101 |   | 00111100 |   | 10101010 |

### Sets
프로그래밍을 하다보면 수학의 subset 개념을 써야하는 순간이 있다. 이를 간단하게 구현할 수 있는 방법이 있다. n개의 element가 있는 set $A = \{0, 1, 2, ..., n-1\}$의 subset을 구하려고 한다. 복잡하게 생각할 것 없이 $a_j = 1$이면 j번째 element를 포함하는 경우를 표현한다고 하자. 아래 예시를 보면 좀 더 쉽게 알 수 있다.

- 01101001 = $\{0, 3, 5, 6\}$
- 01010101 = $\{0, 2, 4, 6\}$
- 00000000 = $\phi$
- 11111111 = A

Set의 operation도 앞에서 배운 비트 연산을 사용하면 쉽게 구현할 수 있다. 
- Intersection(&)
- Union(|)
- Symmetric difference(^)
- Complement(~)

e.g.)
$A = 01101001, B = 01010101$
- A & B = 01000001 = $\{0, 6\}$
- A | B = 01111101 = $\{0, 2, 3, 4, 5, 6\}$
- A ^ B = 00111100 = $\{2, 3, 4, 5 \}$
- ~A = 10010110 = $\{1, 2, 4, 7\}$

### Bit Level Operation
앞서 배운 **&, |, ~, ^**는 int, char, long 등의 표현 방법과 상관없이 비트 단위로 이루어진다.

e.g.)
- ~0x41(0100 0001) -> 0xBE(1011 1110)
- ~0x00(0000 0000) -> 0xFF(1111 1111)
- 0x69(0110 1001) & 0x55(0101 0101) -> 0x41(0100 0001)
- 
### Logic Operation
Bit Level Operation은 비트 단위로 했지만 **Logic Operations(&&, ||, !)**는 전체 수를 기준으로 연산을 진행한다.
e.g.)
- !0x41 -> 0x00
- !0x00 -> 0x01
- !!0x41 -> 0x01

- 0x69 && 0x55 -> 0x01
- 0x69 || 0x55 -> 0x01

### Shift Operations
Left Shift: x << y
비트를 왼쪽으로 y만큼 민 후 빈 공간을 0으로 채운다.

e.g.)
- 01100010 << 3 -> 00010000
- 01100010 << 1 -> 11000100
   
Right Shift: x >> y
- Logical Shift
오른쪽으로 y만큼 민 후 빈 공간을 0으로 채운다.
- Arithmetic Shift
오른쪽으로 y만큼 민 후 빈 공간을 가장 왼쪽의 숫자로 채운다.

e.g.)
- 101000010 Log.>> 3 -> 00010100
- 101000010 Arith.>> 3 -> 11110100

Logical Shift는 비트를 옮겼을 때, 범위를 벗어난 것을 없애고 남은 부분을 0으로 처리하므로 자연스럽다. 반면 Arithmetic Shift는 1로 채우기 때문에 부자연스러워 보인다. 이는 둘의 쓰임이 다르기 때문이다. Logical Shift는 말 그대로 비트를 움직이는 경우에 쓰인다. 즉, 비트 단위에서 의미가 있을 때 사용하게 된다. 하지만 Arithmetic Shift는 수의 크기를 유지하기 위해 이용된다. 이후에 Sign Extension을 보게 될 것이다.

## Integers
- Unsigned Integer $B2U(X) = \sum_{i=0}^{w-1} x_{i}\cdot2^i$
- Two's Complement $B2T(X) = -x_{w-1}\cdot2^{w-1} + \sum_{i=0}^{w-2}x_{i}\cdot2^i$

### Numeric Ranges
- Unsigned Values: 0 ~ $2^w-1$
- Two's Complement Values: $-2^{w-1}$ ~ $2^{w-1}-1$

### Implicit Casting
Casting은 비트의 자료형을 바꿔주는 것이다. 비트는 같지만 자료형이 달라지만 표현하는 숫자가 달라지게 된다. c에서는 직접 `(int) ux`와 같은 형태로 unsigned인 ux를 signed인 int 자료형으로 바꾸는 기능이 있다. 이를 **Explicit Casting**이라고 한다. Explicit Casting은 코드에서 직접 명시하기 때문에 확인하기 쉽다. 문제는 c는 자동으로 자료형을 바꿔주는 기능이 있다는 점이다. 특히, Signed와 Unsigned간의 계산은 signed가 unsigned로 바뀌어서 진행된다. 즉, signed + unsigned 같은 연산이 있으면 signed는 같은 비트를 가지는 unsigned 값으로 바뀌고 unsigned + unsigned 연산으로 처리된다. 이는 signed를 unsigned로 바꾸는 코드가 없어도 자동으로 진행되는데, 이처럼 별다른 표현 없이 자료형을 변화시키는 것을 **Implicit Casting**이라고 한다.

### Sign Extension
w-bit 만큼의 수 x가 있을 때, 비트 자리 수를 w+k-bit로 늘리려고 한다. 이 때, 값을 그대로 유지하려고 한다. unsigned라면 추가한 자리를 0으로 채우면 된다. signed의 경우 제일 앞 자리를 그대로 쓰면 된다. unsigned는 당연하지만, signed는 따로 증명해야 한다. 다만 이를 증명하기 위해선 1자리만 늘리는 경우만 봐도 충분하다. 왜냐하면 k자리를 늘리는 것은 1자리를 늘리는 것을 k번 한 것과 동일하기 때문이다.

proof)

When x is positive, it is trivial. Because sign bit is 0 and the value doesn't change at all. So we only consider about x is negative.
Let $x = -2^{w-1} + \sum_{i=0}^{w-2}a_{i}\cdot2^{i}$, where $a_i \in \{0, 1\}$.

$-2^{w-1} = -2^{w-1} + 0 = -2^{w-1} + (-2^{w-1} + 2^{w-1}) = (-2^{w-1} + -2^{w-1}) + 2^{w-1} = -2^{w} + 2^{w-1}$.

So, $x = -2^{w-1} + \sum_{i=0}^{w-2}a_{i}\cdot2^{i} = -2^{w} + 2^{w-1} + \sum_{i=0}^{w-2}a_{i}\cdot2^{i} = -2^{w} + \sum_{i=0}^{w-1}a_{i}\cdot2^{i}$

Therefore, we can expand 1-digit for x.

위의 경우를 간략하게 자리수를 늘리려면 부호bit를 복사해서 늘리면 된다고 기억하면 된다.

### Truncation
반대로 k+w-bit인 수 x를 앞의 k자리만큼 지우면 어떤 일이 발생하는지 알아보자. unsigned, signed 모두 $mod$ $2^k$연산이 일어난 것과 동일한 결과가 나타난다.

### Addition
- Unsigned $UAdd_w(u, v) = u + v$ $mod$ $2^w$
- Signed $TAdd_w(u, v) = (int)((unsigned)u + (unsigned)v)$

여기서 Unsigned는 수의 범위가 $0$ ~ $2^w - 1$이므로 mod로 쉽게 표현 가능하다. 하지만 Signed는 범위가 $-2^{w-1}$ ~ $2^{w-1}-1$이기 때문에 mod 또한 -값이 되어야 할 때가 있다. 

e.g.)
- $1011u$(11) + $0110u$(6) -> $10001u$(17) -> $0001$($17 \equiv 1$ $mod$ $16$)
- $1011s$(-5) + $0110s$(6) -> $10001s$(-15) ->$0001$($-15 \equiv 1$ $mod$ $16$)

- $1111u$(15) + $1100u$(12) -> $11011u$(27) -> $1011$($27 \equiv 11$ $mod$ $16$) 
- $1111s$(-1) + $1100s$(-4) -> $11011s$(-5) -> $1011$($-5 \equiv -5$ $mod$ $16$)

### Multiplication
Addition과 별로 다른 점은 없다. 하지만 비트가 크게 늘어나기 때문에 버리는 부분이 많을 수 있다.

### Multiply & Divide with shift
u << k는 자리수를 벗어나지 않는다면 $u * 2^k$가 된다. 대부분의 기계는 곱셈보다 shift가 더 빠르다. 하지만 컴파일러가 이를 자동적으로 실행해주기 때문에 크게 신경 쓰지 않아도 된다. 마찬가지로 u >> k는 $\lfloor u/2^k \rfloor$가 된다.

### Why we use Unsigned?
지금까지 Signed와 Unsigned를 적어왔지만 결과적으론 Signed 연산도 잘 정의되어 있기 때문에 Unsigned의 필요성에 의구심이 생길 수 있다. 특히 Unsigned의 Implicit Casting은 생각하지도 못한 오류들을 내놓기도 한다.
```
unsigned i;
for(i = cnt-2; i >= 0; i--)
    a[i] += a[i+1];
```
위의 코드는 i가 unsigned이기 때문에 0보다 작아질 수 없고 for문이 계속 실행되게 된다.
```
#define DELTA sizeof(int)
int i;
for(i = CNT; i-DELTA >= 0; i -= DELTA)
    ...
```
위의 코드도 문제가 될 수 있다. 얼핏 보기엔 잘 모를 수 있지만, sizeof의 반환값은 size_t 타입으로 unsigned value기 때문에, signed와 unsigned의 연산으로 취급되어서 결과값이 unsigned가 된다. 그리고 unsigned는 항상 0이상이기 때문에 조건을 항상 만족해서 계속 실행된다.

보다시피 코드에서 생각하지 못한 오류가 발생할 수 있고 이를 찾아내는 것은 생각보다 오랜 시간이 걸릴 수도 있다. 그래서 Unsigned를 쓰는 경우는 제한적인 것이 좋다. Modular Arithmetic을 실행하거나, Set을 표현할 때처럼 항상 양수만이 필요한 경우에는 Unsigned를 사용한다.

### Byte-Oriented Memory Organization
프로그램은 데이터를 주소로 참조한다. 개념적으로는 메모리를 바이트 array고 adress를 그 배열의 index라고 생각할 수 있다. 이는 실제 메모리와는 동떨어졌지만 주소 개념을 이해하는 것에 도움이 된다. 시스템은 각 process마다 고유 adress를 배치해서, 각자 자기 데이터를 쓰고 지울 수는 있지만 다른 데이터는 그럴 수 없다.

### Word Size
컴퓨터는 각각 **Word Size**가 있는데, 대부분의 기계는 32bits(4bytes)를 word size로 쓰고있다. 이 경우 address의 크기는 4GB($2^32$bytes)가 된다. 4GB는 옛날에는 굉장히 많은 양이지만 요즘에는 그리 큰 양이 아니다. 그래서 더 큰 용량으로 만들기 위해 Word Size를 늘린 64bits 컴퓨터가 나오게 되었다. 메모리 용량이 18EB(exabytes, $18.4 * 10^{18}$)로 굉장히 넉넉한 용량이다. 

### Multibyte Ordering
각 메모리가 Word Size로 나뉘는 것을 알았다. 그런데 이 바이트들을 어떤 순서로 놓을지를 두고 2가지 방법이 있다. 하나는 순서대로 배열하는 것이고 다른 하나는 역순으로 배열하는 것이다. 순서대로 배열하는 것을 **Big Endian**, 역순으로 배열하는 것을 **Little Endian**이라고 한다.

- Big Endian: Sun, Mac
- Little Endian: x86, ios, windows, ARM Android


## Floating Point